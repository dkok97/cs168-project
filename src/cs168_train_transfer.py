# -*- coding: utf-8 -*-
"""cs168-train-transfer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hIOk6RydC3p2frWZxl3YWli4EXkuOWXK
"""

import os, argparse
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import json
from keras.models import model_from_json, load_model

import IPython.display as display
from PIL import Image
import pathlib
import ssl
ssl._create_default_https_context = ssl._create_unverified_context

AUTOTUNE = tf.data.experimental.AUTOTUNE
DS_SIZE = 918
BATCH_SIZE = 16
IMG_SIZE = 256
IMG_HEIGHT = 256
IMG_WIDTH = 256
CLASS_NAMES = None

epochs=20

REPEAT = 0

AUGMENT = 1

base_learning_rate = 0.000001
metrics = [tf.keras.metrics.FalseNegatives(name='fn'),
            tf.keras.metrics.TrueNegatives(name='tn'),
            tf.keras.metrics.FalsePositives(name='fp'), 
            tf.keras.metrics.TruePositives(name='tp'), 
            tf.keras.metrics.BinaryAccuracy(name='accuracy'), 
            tf.keras.metrics.Precision(name='precision'), 
            tf.keras.metrics.Recall(name='recall'),
            tf.keras.metrics.AUC(name='auc')]

#------------PREPARE FOR TRAINING----------------#
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

def get_values(train_dir, validation_dir):
  train_B_dir = os.path.join(train_dir, 'BENIGN')
  train_M_dir = os.path.join(train_dir, 'MALIGNANT')
  validation_B_dir = os.path.join(validation_dir, 'BENIGN')
  validation_M_dir = os.path.join(validation_dir, 'MALIGNANT')

  total_train = len(os.listdir(train_B_dir)) + len(os.listdir(train_M_dir))
  total_val = len(os.listdir(validation_B_dir)) + len(os.listdir(validation_M_dir))

  return total_train, total_val
  
def prepare_data(train_dir, validation_dir, test_dir):
  if AUGMENT:
    train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                                                            rotation_range=45,
                                                                            width_shift_range=.15,
                                                                            height_shift_range=.15,
                                                                            horizontal_flip=True) # Generator for our training data
    validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                                                                rotation_range=45,
                                                                                width_shift_range=.15,
                                                                                height_shift_range=.15,
                                                                                horizontal_flip=True) # Generator for our validation data
    test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,
                                                                          rotation_range=45,
                                                                          width_shift_range=.15,
                                                                          height_shift_range=.15,
                                                                          horizontal_flip=True) # Generator for our test data

    train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                            directory=train_dir,
                                                            shuffle=True,
                                                            target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                            class_mode='binary')
    
    val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                directory=validation_dir,
                                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                class_mode='binary')
    
    test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                directory=test_dir,
                                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                class_mode='binary')
    
    return train_data_gen, val_data_gen, test_data_gen
  else:
    train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
                                                                            
    validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
                                                                                
    test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
                                                                          

    train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                            directory=train_dir,
                                                            shuffle=True,
                                                            target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                            class_mode='binary')
    
    val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                directory=validation_dir,
                                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                class_mode='binary')
    
    test_data_gen = test_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                directory=test_dir,
                                                                target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                class_mode='binary')
    
    return train_data_gen, val_data_gen, test_data_gen


#------------------------------------------------#

#------------LOAD MODEL FROM BASE----------------#

def load_model():
    IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)
    base_model = tf.keras.applications.InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')

    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
    prediction_layer = tf.keras.layers.Dense(1, activation="sigmoid")
    model = tf.keras.Sequential([base_model, global_average_layer, prediction_layer])

    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=metrics)
    # base_learning_rate = 0.0001
    # model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
    #           loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
    #           metrics=['accuracy'])
              
    return model

#------------------------------------------------#

#------------------TRAIN-------------------------#

def train_model(model, train_data_gen, total_train, val_data_gen, total_val, model_name, save=False):
    history = model.fit_generator(
        train_data_gen,
        steps_per_epoch=total_train // BATCH_SIZE,
        epochs=epochs,
        validation_data=val_data_gen,
        validation_steps=total_val // BATCH_SIZE
    )

    if save:
        model.save_weights(model_name+'-weights.h5')
        with open(model_name+'-arch.json', 'w') as f:
          f.write(model.to_json())

    return history

#------------------------------------------------#

train_dir = "/content/drive/My Drive/cs168/train-images"
validation_dir = "/content/drive/My Drive/cs168/val-images"
test_dir = "/content/drive/My Drive/cs168/test-images"
model_name = "/content/drive/My Drive/cs168/transfer-50epoch-256-keras-rms-classweightr"

print("-----------preparing dataset--------------")
total_train, total_val = get_values(train_dir, validation_dir)
train_data_gen, val_data_gen, test_data_gen = prepare_data(train_dir, validation_dir, test_dir)

print(total_train)
print(total_val)

print("-----------loading model--------------")
model = load_model()

print("-----------training--------------")
history = train_model(model, train_data_gen, total_train, val_data_gen, total_val, model_name, save=True)

# TRAINING AND VALIDATION STATISTICS

name = "/content/drive/My Drive/cs168/"

model.evaluate(val_data_gen)
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.ylim(0.5, 0.85)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.ylim(0.4, 0.7)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.savefig(name + 'augment-loss.png')
plt.show()

# LOADING MODEL FROM MEMORY
del model

model_name = "/content/drive/My Drive/cs168/nopretrain-200epoch-256-keras-dropout"
with open(model_name+'-arch.json', 'r') as f:
    model = tf.keras.models.model_from_json(f.read())
model.load_weights(model_name+'-weights.h5')
model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=metrics)

# TESTING THE MODEL ON TEST DATA
import statistics

filenames = test_data_gen.filenames
print(filenames)
stats = model.evaluate(test_data_gen)
print(stats)
# filenames = test_data_gen.filenames
# nb_samples = len(filenames)
# model.predict_generator(test_data_gen,steps = nb_samples)
all_probs = model.predict_proba(test_data_gen)
BEN_probs = []
MAL_probs = []
for i in range(len(filenames)):
  if filenames[i][:3] == 'BEN':
    BEN_probs.append(list(all_probs[i])[0])
  else:
    MAL_probs.append(list(all_probs[i])[0])
print('Median Probability of Malignancy: ', statistics.median(MAL_probs))
print('Average Probability of Malignancy: ', sum(MAL_probs)/len(MAL_probs))

print('Median Probability of Benign: ', statistics.median(BEN_probs))
print('Average Probability of Benign: ', sum(BEN_probs)/len(BEN_probs))

from google.colab import drive
drive.mount('/content/drive')